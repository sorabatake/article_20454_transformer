{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VisionTransformer(宙畑共有)",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBzwgo4cE1oy"
      },
      "source": [
        "**※ GPU環境で利用してください**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBDj3Pkr9kiV"
      },
      "source": [
        "!pip install timm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV_xd_t49VNJ"
      },
      "source": [
        "import argparse\n",
        "import operator\n",
        "import os\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from timm.data import create_dataset, create_loader, resolve_data_config\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import AverageMeter, accuracy\n",
        "from timm.utils.summary import update_summary\n",
        "from torch.autograd import Variable\n",
        "from IPython.display import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiIvbnfBDohq"
      },
      "source": [
        "parser = argparse.ArgumentParser(description=\"Training Config\", add_help=False)\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--opt\",\n",
        "    default=\"sgd\",\n",
        "    type=str,\n",
        "    metavar=\"OPTIMIZER\",\n",
        "    help='Optimizer (default: \"sgd\"',\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--weight-decay\", type=float, default=0.0001, help=\"weight decay (default: 0.0001)\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--lr\", type=float, default=0.01, metavar=\"LR\", help=\"learning rate (default: 0.01)\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--momentum\",\n",
        "    type=float,\n",
        "    default=0.9,\n",
        "    metavar=\"M\",\n",
        "    help=\"Optimizer momentum (default: 0.9)\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--input-size\",\n",
        "    default=None,\n",
        "    nargs=3,\n",
        "    type=int,\n",
        "    metavar=\"N N N\",\n",
        "    help=\"Input all image dimensions (d h w, e.g. --input-size 3 224 224), uses model default if empty\",\n",
        ")\n",
        "\n",
        "args = parser.parse_args([\"--input-size\", \"3\", \"224\", \"224\"])\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiaMWyrvB3gX"
      },
      "source": [
        "# 適宜GoogleColab上のデータセットディレクトリ(train, validation, testが含まれれるディレクトリ)のパスを指定してください\n",
        "dataset_path = '/content/drive/MyDrive/VisionTransformer/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfIcwSUD_hyM"
      },
      "source": [
        "# 対応モデルを確認\n",
        "model_names = timm.list_models(pretrained=True)\n",
        "model_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gPwkJpN_jzB"
      },
      "source": [
        "NUM_FINETUNE_CLASSES = 2 # {'clear': 0, 'cloudy': 1} の2種類\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiD_LiaKF1cb"
      },
      "source": [
        "data_config = resolve_data_config(vars(args), model=model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-mDnZY2_ohl"
      },
      "source": [
        "dataset_train = create_dataset('train', root=os.path.join(dataset_path, 'train'), is_training=True, batch_size=BATCH_SIZE)\n",
        "dataset_eval = create_dataset('validation', root=os.path.join(dataset_path, 'validation'), is_training=False, batch_size=BATCH_SIZE)\n",
        "dataset_test = create_dataset('test', root=os.path.join(dataset_path, 'test'), is_training=False, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0ZAYGEk_2WF"
      },
      "source": [
        "loader_train = create_loader(dataset_train, input_size=data_config['input_size'], batch_size=BATCH_SIZE, is_training=True, num_workers=NUM_WORKERS)\n",
        "loader_eval = create_loader(dataset_eval, input_size=data_config['input_size'], batch_size=BATCH_SIZE, is_training=False, num_workers=NUM_WORKERS)\n",
        "loader_test = create_loader(dataset_test, input_size=data_config['input_size'], batch_size=BATCH_SIZE, is_training=False, num_workers=NUM_WORKERS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "720YBZFE_641"
      },
      "source": [
        "train_loss_fn = nn.CrossEntropyLoss().cuda()\n",
        "validate_loss_fn = nn.CrossEntropyLoss().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLnS3XiTAprE"
      },
      "source": [
        "optimizer = create_optimizer(args, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S8FtVW9Shi3"
      },
      "source": [
        "def train_one_epoch(epoch, model, loader, optimizer, loss_fn, args, output_dir=None):\n",
        "    second_order = hasattr(optimizer, \"is_second_order\") and optimizer.is_second_order\n",
        "    batch_time_m = AverageMeter()\n",
        "    data_time_m = AverageMeter()\n",
        "    losses_m = AverageMeter()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    num_updates = epoch * len(loader)\n",
        "    for _, (input, target) in enumerate(loader):\n",
        "\n",
        "        data_time_m.update(time.time() - end)\n",
        "\n",
        "        output = model(input)\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward(create_graph=second_order)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        num_updates += 1\n",
        "        batch_time_m.update(time.time() - end)\n",
        "\n",
        "        end = time.time()\n",
        "\n",
        "    if hasattr(optimizer, \"sync_lookahead\"):\n",
        "        optimizer.sync_lookahead()\n",
        "\n",
        "    return OrderedDict([(\"loss\", losses_m.avg)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ6tFaXMU5Rf"
      },
      "source": [
        "def validate(model, loader, loss_fn, args):\n",
        "    batch_time_m = AverageMeter()\n",
        "    losses_m = AverageMeter()\n",
        "    accuracy_m = AverageMeter()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for _, (input, target) in enumerate(loader):\n",
        "\n",
        "            input = input.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            output = model(input)\n",
        "\n",
        "            if isinstance(output, (tuple, list)):\n",
        "                output = output[0]\n",
        "\n",
        "            loss = loss_fn(output, target)\n",
        "            acc1, _ = accuracy(output, target, topk=(1, 2))\n",
        "\n",
        "            reduced_loss = loss.data\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "            losses_m.update(reduced_loss.item(), input.size(0))\n",
        "            accuracy_m.update(acc1.item(), output.size(0))\n",
        "\n",
        "            batch_time_m.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "    metrics = OrderedDict([(\"loss\", losses_m.avg), (\"accuracy\", accuracy_m.avg)])\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UsKCxr7PR-O"
      },
      "source": [
        "num_epochs = EPOCHS\n",
        "eval_metric = \"accuracy\"\n",
        "best_metric = None\n",
        "best_epoch = None\n",
        "compare = operator.gt\n",
        "\n",
        "# 学習結果CSVファイルやファインチューニング後のモデルデータの出力先\n",
        "output_dir = \"/content/drive/MyDrive/VisionTransformer/output\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuXndb6FPZjs"
      },
      "source": [
        "for epoch in range(0, num_epochs):\n",
        "    train_metrics = train_one_epoch(\n",
        "        epoch, model, loader_train, optimizer, train_loss_fn, args, output_dir=output_dir\n",
        "    )\n",
        "\n",
        "    eval_metrics = validate(model, loader_eval, validate_loss_fn, args)\n",
        "\n",
        "    if output_dir is not None:\n",
        "        update_summary(\n",
        "            epoch,\n",
        "            train_metrics,\n",
        "            eval_metrics,\n",
        "            os.path.join(output_dir, \"summary.csv\"),\n",
        "            write_header=best_metric is None,\n",
        "        )\n",
        "\n",
        "    metric = eval_metrics[eval_metric]\n",
        "    if best_metric is None or compare(metric, best_metric):\n",
        "        best_metric = metric\n",
        "        best_epoch = epoch\n",
        "        torch.save(model.state_dict(), os.path.join(output_dir, \"best_model.pth\"))\n",
        "\n",
        "    print(epoch)\n",
        "    print(eval_metrics)\n",
        "    print(\"Best metric: {0} (epoch {1})\".format(best_metric, best_epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEiLVHp1lUPC"
      },
      "source": [
        "model.load_state_dict(\n",
        "    torch.load(\n",
        "        os.path.join(output_dir, \"best_model.pth\"), map_location=torch.device(\"cuda\")\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFPVZOkotDkH"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "image_size = data_config[\"input_size\"][-1]\n",
        "loader = transforms.Compose([transforms.Resize(image_size), transforms.ToTensor()])\n",
        "\n",
        "\n",
        "def image_loader(image_name):\n",
        "    image = Image.open(image_name).convert(\"RGB\")\n",
        "    image = loader(image)\n",
        "    image = Variable(image, requires_grad=True)\n",
        "    image = image.unsqueeze(0)\n",
        "    return image.cuda()\n",
        "\n",
        "\n",
        "m = nn.Softmax(dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XuSlpCI63nZ"
      },
      "source": [
        "clear_image_path = os.path.join(dataset_path, 'test/clear/12_3542_1635.png')\n",
        "predicted_clear_image = image_loader(clear_image_path)\n",
        "display(Image.open(clear_image_path))\n",
        "m(model(predicted_clear_image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCFapFT77Rna"
      },
      "source": [
        "cloudy_image_path = os.path.join(dataset_path, 'test/cloudy/12_3503_1735.png')\n",
        "predicted_cloudy_image = image_loader(cloudy_image_path)\n",
        "display(Image.open(cloudy_image_path))\n",
        "m(model(predicted_cloudy_image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFW2zEaEuPhM"
      },
      "source": [
        "def test(model, loader, args):\n",
        "    batch_time_m = AverageMeter()\n",
        "    accuracy_m = AverageMeter()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for _, (input, target) in enumerate(loader):\n",
        "            input = input.cuda()\n",
        "            target = target.cuda()\n",
        "            \n",
        "            output = model(input)\n",
        "\n",
        "            if isinstance(output, (tuple, list)):\n",
        "                output = output[0]\n",
        "\n",
        "            acc1, _ = accuracy(output, target, topk=(1, 2))\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "            accuracy_m.update(acc1.item(), output.size(0))\n",
        "\n",
        "            batch_time_m.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "    return {'accuracy': accuracy_m.avg}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl0YMrTlwXjv"
      },
      "source": [
        "test(model, loader_test, args)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}